{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50.007 Machine Learning Project Part 4\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice: Structured Perceptron\n",
    "\n",
    "Our improved model of choice is the structured perceptron as instead of training on the entire dataset all at once, it looks at a set of training examples at a time. This model is error driven, it will only update its parameters if there is an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from files using UTF-8 encoding\n",
    "with open(\"Data/ES/train\", encoding=\"utf-8\") as f:\n",
    "    es = f.read().split(\"\\n\\n\")\n",
    "with open(\"Data/RU/train\", encoding=\"utf-8\") as f:\n",
    "    ru = f.read().split(\"\\n\\n\")\n",
    "with open(\"Data/ES/dev.in\", encoding=\"utf-8\") as f:\n",
    "    dev_in_es = f.read().split(\"\\n\\n\")\n",
    "with open(\"Data/RU/dev.in\", encoding=\"utf-8\") as f:\n",
    "    dev_in_ru = f.read().split(\"\\n\\n\")\n",
    "\n",
    "cols = [\"idx\", \"word\", \"tag\"]\n",
    "\n",
    "es_train = [pd.DataFrame([[str(idx)] + x.rsplit(\" \", 1) for x in line.splitlines()], columns=cols) for idx, line in enumerate(es)]\n",
    "\n",
    "ru_train = [pd.DataFrame([[str(idx)] + x.rsplit(\" \", 1) for x in line.splitlines()], columns=cols) for idx, line in enumerate(ru)]\n",
    "\n",
    "dev_in_es = [pd.DataFrame([[str(idx), line] for line in line.splitlines()], columns=[cols[:2]]).assign(tag=\"\") for idx, line in enumerate(dev_in_es)]\n",
    "\n",
    "dev_in_ru = [pd.DataFrame([[str(idx), line] for line in line.splitlines()], columns=[cols[:2]]).assign(tag=\"\") for idx, line in enumerate(dev_in_ru)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Perceptron Functions\n",
    "\n",
    "Function parameters X and Y are used to denote the list of words and tags respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_KEYWORD = '!START!'\n",
    "STOP_KEYWORD = '!STOP!'\n",
    "\n",
    "def init_w_trans(tags, init_val):\n",
    "    return pd.DataFrame(init_val, index=tags + [START_KEYWORD], columns=tags + [STOP_KEYWORD])\n",
    "\n",
    "def init_w_emit(tags):\n",
    "    return pd.DataFrame(0, index=[], columns=tags)\n",
    "\n",
    "def create_features_trans(Y: pd.Series, tags):\n",
    "    phi = init_w_trans(tags, 0)\n",
    "    for i in range(Y.size + 1):\n",
    "        if i == 0: first_tag = START_KEYWORD\n",
    "        else: first_tag = Y[i-1]\n",
    "        if i == Y.size: next_tag = STOP_KEYWORD\n",
    "        else: next_tag = Y[i]\n",
    "        phi.loc[first_tag, next_tag] += 1\n",
    "    return phi\n",
    "\n",
    "def create_features_emit(X: pd.Series, Y: pd.Series, tags):\n",
    "    phi = pd.DataFrame(0, index=Y.index, columns=tags)\n",
    "    for tag in tags:\n",
    "        phi.loc[Y.loc[:] == tag, tag] = 1\n",
    "    phi = pd.concat([X, phi], axis=1)\n",
    "    phi = phi.groupby('word')[tags].sum().reset_index()\n",
    "    phi.index = phi['word'].values\n",
    "    phi = phi.drop('word', axis=1)\n",
    "    return phi\n",
    "    \n",
    "\n",
    "def hmm_viterbi(w_trans: pd.DataFrame, w_emit: pd.DataFrame, X: pd.Series, tags):\n",
    "    if (X.size == 0):\n",
    "        return pd.Series()\n",
    "    best_edge = pd.DataFrame('', index=X.index, columns=tags)\n",
    "    best_score = pd.DataFrame(0, index=X.index, columns=tags)\n",
    "    expander = pd.DataFrame(1, index=[0], columns=tags)\n",
    "    \n",
    "    trans = w_trans.loc[tags, tags].T\n",
    "    \n",
    "    # From start\n",
    "    trans_filtered = w_trans.loc[[START_KEYWORD], tags].reset_index(drop=True)\n",
    "    emit_transpose = w_emit.loc[[X[0]]] if X[0] in w_emit.index else pd.DataFrame(0, index=[0], columns=tags)\n",
    "    emit_transpose = emit_transpose.reset_index(drop=True)\n",
    "    trans_emit = trans_filtered + emit_transpose\n",
    "    best_score.loc[0, :] = trans_emit.values\n",
    "    best_edge.loc[0, :] = START_KEYWORD\n",
    "    # Middle to end\n",
    "    for i in range(0, X.shape[0]):\n",
    "        emit_transpose = w_emit.loc[[X[i]]] if X[i] in w_emit.index else pd.DataFrame(0, index=[0], columns=tags)\n",
    "        emit_transpose = emit_transpose.reset_index(drop=True).T @ expander\n",
    "        trans_emit = best_score.loc[[i]].reset_index(drop=True).squeeze() + trans + emit_transpose\n",
    "        best_score.loc[i+1, :] = trans_emit.max().values\n",
    "        best_edge.loc[i+1, :] = trans_emit.idxmax().values\n",
    "        \n",
    "    # # Backtracking to find best state sequence\n",
    "    best_seq = []\n",
    "    curr_state = best_score.loc[best_score.shape[0] - 1].idxmax()\n",
    "    for i in range(best_edge.shape[0] - 1, -1, -1):\n",
    "        best_seq.append(curr_state)\n",
    "        curr_state = best_edge.loc[i, curr_state]\n",
    "    best_seq.reverse()\n",
    "    return pd.Series(best_seq)\n",
    "\n",
    "def structured_perceptron(data, tags, iters):\n",
    "    w_trans = init_w_trans(tags, 1)\n",
    "    w_emit = init_w_emit(tags)\n",
    "    for iteration in range(iters):\n",
    "        for idx in range(len(data)):\n",
    "            X = data[idx].loc[:, 'word']\n",
    "            X = X.squeeze() if isinstance(X, pd.DataFrame) else X\n",
    "            Y_prime = data[idx].loc[:, 'tag']\n",
    "            Y_prime = Y_prime.squeeze() if isinstance(Y_prime, pd.DataFrame) else Y_prime\n",
    "            Y_hat = hmm_viterbi(w_trans, w_emit, X, tags)\n",
    "            phi_prime_trans = create_features_trans(Y_prime, tags)\n",
    "            phi_prime_emit = create_features_emit(X, Y_prime, tags)\n",
    "            phi_hat_trans = create_features_trans(Y_hat, tags)\n",
    "            phi_hat_emit = create_features_emit(X, Y_hat, tags)\n",
    "            w_trans += phi_prime_trans - phi_hat_trans\n",
    "            w_emit = w_emit.add(phi_prime_emit.sub(phi_hat_emit, fill_value=0), fill_value=0)\n",
    "    return w_trans, w_emit\n",
    "\n",
    "def predict(test_data, w_trans,  w_emit, tags):\n",
    "    pred_data = []\n",
    "    for idx in range(len(test_data)):\n",
    "        data_instance = test_data[idx]\n",
    "        X = data_instance.loc[:, ['word']].squeeze()\n",
    "        X = pd.Series(X)\n",
    "        Y_pred = hmm_viterbi(w_trans, w_emit, X, tags)\n",
    "        data_instance['tag'] = Y_pred\n",
    "        pred_data.append(data_instance)\n",
    "    return pred_data\n",
    "\n",
    "def result_to_str(df_list):\n",
    "    res_str = []\n",
    "    for df in df_list:\n",
    "        res_str.append(df.drop('idx', axis=1).to_csv(sep=' ', header=None, index=False, lineterminator=\"\\n\"))\n",
    "    res_str = \"\\n\".join(res_str)\n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['O', 'B-positive', 'B-neutral', 'B-negative', 'I-positive', 'I-neutral', 'I-negative']\n",
    "epoch = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_benchmark = True\n",
    "benchmark_amount = 100 # number of tests to run to get a rough time value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Running benchmark with sample size of 100\n",
      "=============================================================\n",
      "Benchmarking es_train...\n",
      "Time elapsed: 2s\n",
      "Training es_train with 5 iterations will take an estimated 3.0m 44s\n",
      "Benchmarking ru_train...\n",
      "Time elapsed: 2s\n",
      "Training ru_train with 5 iterations will take an estimated 3.0m 23s\n",
      "=============================================================\n",
      "Benchmark complete\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "if run_benchmark:\n",
    "    print(\"=============================================================\")\n",
    "    print(f\"Running benchmark with sample size of {benchmark_amount}\")\n",
    "    print(\"=============================================================\")\n",
    "\n",
    "    print(\"Benchmarking es_train...\")\n",
    "    start = time.perf_counter()\n",
    "    structured_perceptron(random.sample(ru_train, benchmark_amount), tags, 1)\n",
    "    stop = time.perf_counter()\n",
    "    print(f\"Time elapsed: {round(stop - start)}s\")\n",
    "    estimated_total_time = (stop - start) * (len(es_train) / benchmark_amount) * epoch\n",
    "    print(f\"Training es_train over {epoch} epoch will take an estimated {estimated_total_time // 60}m {round(estimated_total_time % 60)}s\")\n",
    "\n",
    "    print(\"Benchmarking ru_train...\")\n",
    "    start = time.perf_counter()\n",
    "    structured_perceptron(random.sample(ru_train, benchmark_amount), tags, 1)\n",
    "    stop = time.perf_counter()\n",
    "    print(f\"Time elapsed: {round(stop - start)}s\")\n",
    "    estimated_total_time = (stop - start) * (len(es_train) / benchmark_amount) * epoch\n",
    "    print(f\"Training ru_train over {epoch} epoch will take an estimated {estimated_total_time // 60}m {round(estimated_total_time % 60)}s\")\n",
    "\n",
    "    print(\"=============================================================\")\n",
    "    print(f\"Benchmark complete\")\n",
    "    print(\"=============================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[323], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w_trans_es, w_emit_es \u001b[39m=\u001b[39m structured_perceptron(es_train, tags, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m display(w_trans_es)\n\u001b[0;32m      3\u001b[0m display(w_emit_es)\n",
      "Cell \u001b[1;32mIn[319], line 73\u001b[0m, in \u001b[0;36mstructured_perceptron\u001b[1;34m(data, tags, iters)\u001b[0m\n\u001b[0;32m     71\u001b[0m Y_prime \u001b[39m=\u001b[39m data[idx]\u001b[39m.\u001b[39mloc[:, \u001b[39m'\u001b[39m\u001b[39mtag\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     72\u001b[0m Y_prime \u001b[39m=\u001b[39m Y_prime\u001b[39m.\u001b[39msqueeze() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Y_prime, pd\u001b[39m.\u001b[39mDataFrame) \u001b[39melse\u001b[39;00m Y_prime\n\u001b[1;32m---> 73\u001b[0m Y_hat \u001b[39m=\u001b[39m hmm_viterbi(w_trans, w_emit, X, tags)\n\u001b[0;32m     74\u001b[0m phi_prime_trans \u001b[39m=\u001b[39m create_features_trans(Y_prime, tags)\n\u001b[0;32m     75\u001b[0m phi_prime_emit \u001b[39m=\u001b[39m create_features_emit(X, Y_prime, tags)\n",
      "Cell \u001b[1;32mIn[319], line 52\u001b[0m, in \u001b[0;36mhmm_viterbi\u001b[1;34m(w_trans, w_emit, X, tags)\u001b[0m\n\u001b[0;32m     50\u001b[0m     emit_transpose \u001b[39m=\u001b[39m emit_transpose\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m expander\n\u001b[0;32m     51\u001b[0m     trans_emit \u001b[39m=\u001b[39m best_score\u001b[39m.\u001b[39mloc[[i]]\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39msqueeze() \u001b[39m+\u001b[39m trans \u001b[39m+\u001b[39m emit_transpose\n\u001b[1;32m---> 52\u001b[0m     best_score\u001b[39m.\u001b[39;49mloc[i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m, :] \u001b[39m=\u001b[39m trans_emit\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     53\u001b[0m     best_edge\u001b[39m.\u001b[39mloc[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, :] \u001b[39m=\u001b[39m trans_emit\u001b[39m.\u001b[39midxmax()\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     55\u001b[0m \u001b[39m# # Backtracking to find best state sequence\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Seah Ying Xiang\\OneDrive - Singapore University of Technology and Design\\Course Documents\\TERM 5\\50.007 Machine Learning\\Project\\Machine-Learning-Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 849\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Seah Ying Xiang\\OneDrive - Singapore University of Technology and Design\\Course Documents\\TERM 5\\50.007 Machine Learning\\Project\\Machine-Learning-Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1716\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1714\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(value\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m value\n\u001b[0;32m   1715\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39marrays[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1716\u001b[0m     take_split_path \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m can_hold_element(\n\u001b[0;32m   1717\u001b[0m         arr, extract_array(val, extract_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1718\u001b[0m     )\n\u001b[0;32m   1720\u001b[0m \u001b[39m# if we have any multi-indexes that have non-trivial slices\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m \u001b[39m# (not null slices) then we must take the split path, xref\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[39m# GH 10360, GH 27841\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(indexer, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(indexer) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39maxes):\n",
      "File \u001b[1;32mc:\\Users\\Seah Ying Xiang\\OneDrive - Singapore University of Technology and Design\\Course Documents\\TERM 5\\50.007 Machine Learning\\Project\\Machine-Learning-Project\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1744\u001b[0m, in \u001b[0;36mcan_hold_element\u001b[1;34m(arr, element)\u001b[0m\n\u001b[0;32m   1741\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1744\u001b[0m     np_can_hold_element(dtype, element)\n\u001b[0;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, LossySetitemError):\n",
      "File \u001b[1;32mc:\\Users\\Seah Ying Xiang\\OneDrive - Singapore University of Technology and Design\\Course Documents\\TERM 5\\50.007 Machine Learning\\Project\\Machine-Learning-Project\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1796\u001b[0m, in \u001b[0;36mnp_can_hold_element\u001b[1;34m(dtype, element)\u001b[0m\n\u001b[0;32m   1794\u001b[0m     casted \u001b[39m=\u001b[39m element\u001b[39m.\u001b[39mastype(dtype)\n\u001b[0;32m   1795\u001b[0m comp \u001b[39m=\u001b[39m casted \u001b[39m==\u001b[39m element\n\u001b[1;32m-> 1796\u001b[0m \u001b[39mif\u001b[39;00m comp\u001b[39m.\u001b[39;49mall():\n\u001b[0;32m   1797\u001b[0m     \u001b[39m# Return the casted values bc they can be passed to\u001b[39;00m\n\u001b[0;32m   1798\u001b[0m     \u001b[39m#  np.putmask, whereas the raw values cannot.\u001b[39;00m\n\u001b[0;32m   1799\u001b[0m     \u001b[39m#  see TestSetitemFloatNDarrayIntoIntegerSeries\u001b[39;00m\n\u001b[0;32m   1800\u001b[0m     \u001b[39mreturn\u001b[39;00m casted\n\u001b[0;32m   1801\u001b[0m \u001b[39mraise\u001b[39;00m LossySetitemError\n",
      "File \u001b[1;32mc:\\Users\\Seah Ying Xiang\\OneDrive - Singapore University of Technology and Design\\Course Documents\\TERM 5\\50.007 Machine Learning\\Project\\Machine-Learning-Project\\.venv\\Lib\\site-packages\\numpy\\core\\_methods.py:61\u001b[0m, in \u001b[0;36m_all\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[39m=\u001b[39mwhere)\n\u001b[1;32m---> 61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_all\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     62\u001b[0m     \u001b[39m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m where \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         \u001b[39mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w_trans_es, w_emit_es = structured_perceptron(es_train, tags, 1)\n",
    "display(w_trans_es)\n",
    "display(w_emit_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_out_es_p4 = predict(dev_in_es, w_trans_es, w_emit_es, tags)\n",
    "file_out_es_p4 = result_to_str(dev_out_es_p4)\n",
    "with codecs.open(\"Data/ES/dev.p4.out\", \"w\", \"utf-8\") as f:\n",
    "    f.write(file_out_es_p4)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>I-negative</th>\n",
       "      <th>!STOP!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>382</td>\n",
       "      <td>-1566</td>\n",
       "      <td>120</td>\n",
       "      <td>379</td>\n",
       "      <td>-52</td>\n",
       "      <td>-20</td>\n",
       "      <td>-1589</td>\n",
       "      <td>3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-positive</th>\n",
       "      <td>1481</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>351</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-neutral</th>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-20</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-negative</th>\n",
       "      <td>-1738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-positive</th>\n",
       "      <td>349</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-33</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-neutral</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-22</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-negative</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!START!</th>\n",
       "      <td>-62</td>\n",
       "      <td>343</td>\n",
       "      <td>65</td>\n",
       "      <td>-192</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               O  B-positive  B-neutral  B-negative  I-positive  I-neutral  \\\n",
       "O            382       -1566        120         379         -52        -20   \n",
       "B-positive  1481           4          0         -19         351          1   \n",
       "B-neutral    176           1          1         -20           1         29   \n",
       "B-negative -1738           1          1          -6           1          1   \n",
       "I-positive   349          -2          1         -33         248          1   \n",
       "I-neutral     29           1          1         -22           1         26   \n",
       "I-negative    82           1          1       -1743           1          1   \n",
       "!START!      -62         343         65        -192           1         -1   \n",
       "\n",
       "            I-negative  !STOP!  \n",
       "O                -1589    3045  \n",
       "B-positive          -5   -3030  \n",
       "B-neutral            1       1  \n",
       "B-negative          83       1  \n",
       "I-positive           1     -13  \n",
       "I-neutral            1       1  \n",
       "I-negative          43       2  \n",
       "!START!           -147       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-positive</th>\n",
       "      <th>B-neutral</th>\n",
       "      <th>B-negative</th>\n",
       "      <th>I-positive</th>\n",
       "      <th>I-neutral</th>\n",
       "      <th>I-negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ячменное</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>–</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>…</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>№</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7880 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             O  B-positive  B-neutral  B-negative  I-positive  I-neutral  \\\n",
       "!          8.0         0.0        0.0        -3.0        -1.0        0.0   \n",
       "\"        -17.0         5.0        2.0       -16.0        27.0        4.0   \n",
       "%          2.0         0.0        0.0        -1.0         0.0        0.0   \n",
       "&         -1.0         0.0        0.0         0.0         2.0        0.0   \n",
       "'          0.0         0.0        0.0         0.0         0.0        0.0   \n",
       "...        ...         ...        ...         ...         ...        ...   \n",
       "ячменное  -1.0         0.0        0.0         0.0         1.0        0.0   \n",
       "–          0.0         0.0        0.0         0.0         0.0        0.0   \n",
       "—          0.0         0.0        0.0         0.0         0.0        0.0   \n",
       "…          0.0         0.0        0.0         0.0         0.0        0.0   \n",
       "№         -1.0         0.0        0.0         0.0         1.0        0.0   \n",
       "\n",
       "          I-negative  \n",
       "!               -4.0  \n",
       "\"               -5.0  \n",
       "%               -1.0  \n",
       "&               -1.0  \n",
       "'                0.0  \n",
       "...              ...  \n",
       "ячменное         0.0  \n",
       "–                0.0  \n",
       "—                0.0  \n",
       "…                0.0  \n",
       "№                0.0  \n",
       "\n",
       "[7880 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_trans_ru, w_emit_ru = structured_perceptron(ru_train, tags, 1)\n",
    "display(w_trans_ru)\n",
    "display(w_emit_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_out_ru_p4 = predict(dev_in_ru, w_trans_ru, w_emit_ru, tags)\n",
    "file_out_ru_p4 = result_to_str(dev_out_ru_p4)\n",
    "with codecs.open(\"Data/RU/dev.p4.out\", \"w\", \"utf-8\") as f:\n",
    "    f.write(file_out_ru_p4)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Part 4 ES prediction results\n",
      "============================\n",
      "Epoch: 1\n",
      "\n",
      "#Entity in gold data: 229\n",
      "#Entity in prediction: 1834\n",
      "\n",
      "#Correct Entity : 160\n",
      "Entity  precision: 0.0872\n",
      "Entity  recall: 0.6987\n",
      "Entity  F: 0.1551\n",
      "\n",
      "#Correct Sentiment : 41\n",
      "Sentiment  precision: 0.0224\n",
      "Sentiment  recall: 0.1790\n",
      "Sentiment  F: 0.0397\n",
      "\n",
      "============================\n",
      "Part 4 RU prediction results\n",
      "============================\n",
      "Epoch: 1\n",
      "\n",
      "#Entity in gold data: 389\n",
      "#Entity in prediction: 256\n",
      "\n",
      "#Correct Entity : 82\n",
      "Entity  precision: 0.3203\n",
      "Entity  recall: 0.2108\n",
      "Entity  F: 0.2543\n",
      "\n",
      "#Correct Sentiment : 20\n",
      "Sentiment  precision: 0.0781\n",
      "Sentiment  recall: 0.0514\n",
      "Sentiment  F: 0.0620\n"
     ]
    }
   ],
   "source": [
    "print(\"============================\")\n",
    "print(\"Part 4 ES prediction results\")\n",
    "print(\"============================\")\n",
    "print(f\"Epoch: {epoch}\")\n",
    "!python EvalScript/evalResult.py Data/ES/dev.out Data/ES/dev.p4.out\n",
    "\n",
    "print(\"\\n============================\")\n",
    "print(\"Part 4 RU prediction results\")\n",
    "print(\"============================\")\n",
    "print(f\"Epoch: {epoch}\")\n",
    "!python EvalScript/evalResult.py Data/RU/dev.out Data/RU/dev.p4.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
