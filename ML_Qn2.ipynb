{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50.007 Machine Learning Project Part 2\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "from itertools import groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3966961907.py, line 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 100\u001b[1;36m\u001b[0m\n\u001b[1;33m    if line.strip(.r):  # Skip empty lines\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "\n",
    "# Function to estimate transition parameters using MLE\n",
    "# Function to estimate transition parameters using MLE\n",
    "def estimate_transition_parameters_train(train_data):\n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    state_counts = defaultdict(int)\n",
    "\n",
    "    for sentence in train_data:\n",
    "        prev_state = 'START'\n",
    "        for word, state in sentence:\n",
    "            transition_counts[prev_state][state] += 1\n",
    "            state_counts[prev_state] += 1\n",
    "            prev_state = state\n",
    "        transition_counts[prev_state]['END'] += 1\n",
    "\n",
    "    # Calculate transition probabilities\n",
    "    transition_params = defaultdict(dict)\n",
    "    for from_state, to_states in transition_counts.items():\n",
    "        for to_state, count in to_states.items():\n",
    "            transition_params[from_state][to_state] = count / state_counts[from_state]\n",
    "            \n",
    "    return transition_params\n",
    "\n",
    "\n",
    "# Function to estimate emission parameters using MLE\n",
    "def estimate_emission_params(train_data):\n",
    "    word_sentiment_counts = defaultdict(lambda: defaultdict(int))\n",
    "    sentiment_counts = defaultdict(int)\n",
    "    \n",
    "    for sentence in train_data:\n",
    "        for word, label in sentence:\n",
    "            sentiment_counts[label] += 1\n",
    "            word_sentiment_counts[label][word] += 1\n",
    "            \n",
    "    emission_params = {}\n",
    "    for label, word_counts in word_sentiment_counts.items():\n",
    "        total_label_count = sentiment_counts[label]\n",
    "        for word, count in word_counts.items():\n",
    "            emission_params[(word, label)] = count / total_label_count\n",
    "            \n",
    "    return emission_params\n",
    "\n",
    "# Viterbi Algorithm Implementation\n",
    "def viterbi_algorithm(sentence, transition_params, emission_params, states):\n",
    "    n = len(sentence)\n",
    "    num_states = len(states)\n",
    "    viterbi = [{} for _ in range(n)]\n",
    "    backpointers = [{} for _ in range(n)]\n",
    "\n",
    "    # Initialization at time step 0\n",
    "    for state in states:\n",
    "        emission_prob = emission_params.get((sentence[0][0], state), 1e-10)\n",
    "        viterbi[0][state] = math.log(transition_params['START'].get(state, 1e-10)) + math.log(emission_prob)\n",
    "        backpointers[0][state] = 'START'\n",
    "\n",
    "    # Forward pass\n",
    "    for t in range(1, n):\n",
    "        for state in states:\n",
    "            max_prob = float('-inf')\n",
    "            prev_state = None\n",
    "            for prev_state in states:\n",
    "                transition_prob = transition_params[prev_state].get(state, 1e-10)\n",
    "                emission_prob = emission_params.get((sentence[t][0], state), 1e-10)\n",
    "                prob = viterbi[t - 1].get(prev_state, 1e-10) + math.log(transition_prob) + math.log(emission_prob)\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    backpointers[t][state] = prev_state\n",
    "            viterbi[t][state] = max_prob\n",
    "\n",
    "    # Termination step\n",
    "    max_prob = float('-inf')\n",
    "    final_state = None\n",
    "    for state in states:\n",
    "        transition_prob = transition_params[state].get('END', 1e-10)\n",
    "        prob = viterbi[n - 1][state] + math.log(transition_prob)\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            final_state = state\n",
    "\n",
    "    # Backtracking step\n",
    "    best_path = [final_state]\n",
    "    for t in range(n - 1, 0, -1):\n",
    "        best_path.insert(0, backpointers[t][best_path[0]])\n",
    "\n",
    "    return best_path\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_data(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        data = f.read().splitlines()\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    sentence = []\n",
    "    for line in data:\n",
    "        if line.strip(\".r\"):  # Skip empty lines\n",
    "            parts = line.split(\" \")\n",
    "            if len(parts) != 2:\n",
    "                print(\"Invalid line format:\", line)\n",
    "                continue  # Skip this line\n",
    "            word, label = parts\n",
    "            sentence.append((word, label))\n",
    "        else:\n",
    "            processed_data.append(sentence)\n",
    "            sentence = []\n",
    "    return processed_data\n",
    "\n",
    "def write_output(filename, predicted_tags):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for tags in predicted_tags:\n",
    "            f.write(\" \".join(tags) + \"\\n\")\n",
    "\n",
    "# Load and preprocess the training data\n",
    "train_data_es = load_data(\"Data/ES/train\")\n",
    "train_data_ru = load_data(\"Data/RU/train\")\n",
    "train_data_es = preprocess_data(train_data_es)\n",
    "train_data_ru = preprocess_data(train_data_ru)\n",
    "\n",
    "# Estimate model parameters using MLE\n",
    "transition_params_es = estimate_transition_parameters_train(train_data_es)\n",
    "transition_params_ru = estimate_transition_parameters_train(train_data_ru)\n",
    "emission_params_es = estimate_emission_params(train_data_es)\n",
    "emission_params_ru = estimate_emission_params(train_data_ru)\n",
    "\n",
    "# Load and preprocess the development data\n",
    "dev_data_in_es = load_data(\"Data/ES/dev.in\")\n",
    "dev_data_in_es = preprocess_data(dev_data_in_es)\n",
    "\n",
    "# Define the states (tags)\n",
    "states_es = list(emission_params_es.keys())\n",
    "states_ru = list(emission_params_ru.keys())\n",
    "\n",
    "# Run Viterbi algorithm on the development set using the learned models\n",
    "predicted_tags_es = []\n",
    "for sentence in dev_data_in_es:\n",
    "    predicted_tags_es.append(viterbi_algorithm(sentence, transition_params_es, emission_params_es, states_es))\n",
    "\n",
    "# Write the output to a file (dev.p2.out)\n",
    "write_output(\"dev.p2.out\", predicted_tags_es)\n",
    "\n",
    "# Define a function to calculate precision, recall, and F-score\n",
    "def calculate_metrics(true_tags, predicted_tags, states):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for true_seq, pred_seq in zip(true_tags, predicted_tags):\n",
    "        for true, pred in zip(true_seq, pred_seq):\n",
    "            if true == pred and true != 'O':\n",
    "                tp += 1\n",
    "            elif true != pred and true != 'O' and pred != 'O':\n",
    "                fp += 1\n",
    "                fn += 1\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return precision, recall, f_score\n",
    "\n",
    "# Calculate and print precision, recall, and F-score for ES\n",
    "true_tags_es = load_data(\"Data/ES/dev.out\")\n",
    "true_tags_es = preprocess_data(true_tags_es)\n",
    "precision_es, recall_es, f_score_es = calculate_metrics(true_tags_es, predicted_tags_es, states_es)\n",
    "print(\"ES Precision:\", precision_es)\n",
    "print(\"ES Recall:\", recall_es)\n",
    "print(\"ES F-score:\", f_score_es)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
